#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Usage:
    autoupdate_worker --port <port> [options]

Arguments:
    <port> -- The port to run the server on.

Options:
    --logging (debug | info | error)
    --log_file <log_file> also log to a file
"""

import BaseHTTPServer
import errno
import logging
import os.path
import os
import shutil
import subprocess
import tarfile
import time

from docopt import docopt
import git
import gitenberg
import gitenberg.travis
import requests

from gitenberg_autoupdate import __version__, queue, util

RDF_URL = "https://www.gutenberg.org/cache/epub/feeds/rdf-files.tar.bz2"
RDF_PATH = "/tmp/rdf.tar.bz2"
RDF_EXTRACT_PATH = "/tmp/extracted_rdf"
# 1 day
RDF_MAX_AGE = 60 * 60 * 24
GITENSITE_YAML_URL = "https://gitenberg.org/books/post/"
# header: x-gitenberg-secret
GITENBERG_SECRET = os.environ['GITENBERG_SECRET']


def download_rdf():
  """Ensures a fresh-enough RDF file is downloaded and extracted.

  Returns True on error."""

  if (os.path.exists(RDF_PATH) and
      (time.time() - os.path.getmtime(RDF_PATH)) < RDF_MAX_AGE):
    return False

  logging.info('Re-downloading RDF library from %s' % RDF_URL)
  try:
    shutil.rmtree(RDF_EXTRACT_PATH)
  except OSError as e:
    # Ignore not finding the directory to remove.
    if e.errno != errno.ENOENT:
      raise

  try:
    with open(RDF_PATH, 'w') as f:
      with requests.get(RDF_URL, stream=True) as r:
        shutil.copyfileobj(r.raw, f)
  except requests.exceptions.RequestException as e:
    logging.error(e)
    return True

  try:
    with tarfile.open(RDF_PATH, 'r') as f:
      f.extractall(RDF_EXTRACT_PATH)
  except tarfile.TarError as e:
    logging.error(e)
    try:
      os.unlink(RDF_PATH)
    except:
      pass
    return True

  return False

class RequestHandler(BaseHTTPServer.BaseHTTPRequestHandler):
  def do_GET(self):
    if self.path != '/health':
      self.send_error(404)
      return

    # Claim we're alive and healthy if we're responding to this GET.
    self.send_response(200)
    self.end_headers()

  def do_POST(self):
    if self.path != '/do_update':
      self.send_error(404)
      return

    if 'Content-Length' not in self.headers:
      self.send_error(400)
      return

    if download_rdf():
      self.send_error(500)
      return

    content_length = int(self.headers['Content-Length'])
    payload_string = self.rfile.read(content_length)
    logging.info('Got a message for %s' % payload_string)

    # First write something so that the nginx server upstream doesn't time out
    # even if building the book takes a while.
    self.wfile.write('%s ' % self.protocol_version)

    if not process_queued_update(payload_string):
        self.wfile.write('%d %s\r\n' % (500, 'Error'))
        self.send_header('Connection', 'close')
        self.end_headers()
        return

    self.wfile.write('%d %s\r\n' % (200, 'OK'))
    self.send_header('Connection', 'close')
    self.end_headers()

class cd:
    """Context manager for changing the current working directory"""
    def __init__(self, newPath):
        self.newPath = os.path.expanduser(newPath)

    def __enter__(self):
        self.savedPath = os.getcwd()
        os.chdir(self.newPath)

    def __exit__(self, etype, value, traceback):
        os.chdir(self.savedPath)

def make_ebook(b):
    with cd(b.local_path):
        gitenberg.travis.build_epub()
        subprocess.check_call(('ebook-convert', 'book.epub', 'book.mobi'))
        subprocess.check_call(('xvfb-run', 'ebook-convert', 'book.epub', 'book.pdf'))
        # TODO: Make a release out of these once Travis stops doing that for us,
        # and only if this push event is of a tag.

def process_queued_update(repo_name):
    repo_name_tag = [repo_name] if isinstance(repo_name, int) else repo_name.split(' ', 1)
    (repo_name, tag) = repo_name_tag if len(repo_name_tag) == 2 else (repo_name, None)
    # intialize book
    b = gitenberg.actions.get_book(repo_name)
    if b.local_path:
        b.remove()
    try:
        b.clone_from_github() # if no local version, clones

        # if it previously existed as a local repo, need to pull
        repo = b.local_repo.git
        if not repo.remote('origin'): # must exist
            logging.error("No origin for %s" % repo_name)
            return False
        repo.remote('origin').pull()

        b.parse_book_metadata() # in case this changed
        b.add_covers() # checks for covers, if none, makes one, adds to metadata
        
        if tag:
            b.meta.metadata['_version'] = tag
            
        b.save_meta() # save the new metadata in yaml format

        b.local_repo.add_all_files() # untracked only
        repo.git.add(update=True) # tracked ones too

        if repo.git.status("--porcelain"):
            logging.info('Have changes, so pushing and then building')
            # We made changes to the repo, so commit them.
            repo.index.commit("Machine generated yaml, cover")

            # returns a list, one PushInfo per head. We have one head
            ret = repo.remote('origin').push(repo.refs.master)[0]
            if ret.flags & git.remote.PushInfo.ERROR:
                logging.error('Pushing returned %s' % ret)
                return False
            if tag:
                make_ebook(b) # make ebook files
        else:
            logging.info('No changes')

        headers = {'x-gitenberg-secret': GITENBERG_SECRET}
        response = requests.post(GITENSITE_YAML_URL, b.meta.__unicode__(), headers=headers)
        logging.info('Got from gitensite: %s' % response)
        return response.ok
    finally:
        # Make sure to always remove it to avoid filling up the disk.
        if b.local_path:
            b.remove()

    return True

if __name__ == '__main__':
  arguments = docopt(__doc__, version=__version__)

  util.setup_logging(arguments)

  port = int(arguments.get('<port>', '80'))

  server = BaseHTTPServer.HTTPServer(('0.0.0.0', port), RequestHandler)
  try:
    server.serve_forever()
  except KeyboardInterrupt:
    pass
  server.server_close()
