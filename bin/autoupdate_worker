#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Usage:
    autoupdate_worker --port <port> [options]

Arguments:
    <port> -- The port to run the server on.

Options:
    --logging (debug | info | error)
    --log_file <log_file> also log to a file
"""

import BaseHTTPServer
import errno
import logging
import os.path
import os
import shutil
import subprocess
import tarfile
import time

import git
import gitenberg
import requests

from docopt import docopt

from gitenberg_autoupdate import __version__, ebooks, queue, util, webhooks

RDF_URL = "https://www.gutenberg.org/cache/epub/feeds/rdf-files.tar.bz2"
RDF_PATH = "/tmp/rdf.tar.bz2"
RDF_EXTRACT_PATH = "/tmp/extracted_rdf"
# 1 day
RDF_MAX_AGE = 60 * 60 * 24

class Rdfcache(object):
    downloading = False
    
    def download_rdf(self):
        """Ensures a fresh-enough RDF file is downloaded and extracted.

        Returns True on error."""
        if self.downloading:
            return True
        
        if (os.path.exists(RDF_PATH) and
                (time.time() - os.path.getmtime(RDF_PATH)) < RDF_MAX_AGE):
            return False
        self.downloading = True
        logging.info('Re-downloading RDF library from %s' % RDF_URL)
        try:
            shutil.rmtree(RDF_EXTRACT_PATH)
        except OSError as e:
            # Ignore not finding the directory to remove.
            if e.errno != errno.ENOENT:
                raise

        try:
            with open(RDF_PATH, 'w') as f:
                with requests.get(RDF_URL, stream=True) as r:
                    shutil.copyfileobj(r.raw, f)
        except requests.exceptions.RequestException as e:
            logging.error(e)
            return True

        try:
            with tarfile.open(RDF_PATH, 'r') as f:
                f.extractall(RDF_EXTRACT_PATH)
        except tarfile.TarError as e:
            logging.error(e)
            try:
                os.unlink(RDF_PATH)
            except:
                pass
            return True
        self.downloading = False
        return False

class RequestHandler(BaseHTTPServer.BaseHTTPRequestHandler):
    _rdfcache = None
    def download_rdf(self):
        if not self._rdfcache:
            self._rdfcache = Rdfcache()
        return self._rdfcache.download_rdf()

    def do_GET(self):
        if self.path != '/health':
            self.send_error(404)
            return
        
        # if the rdf cache ins't ready, we're not healthy
        if self.download_rdf():
            self.send_error(500)
            return

        # Claim we're alive and healthy if we're responding to this GET.
        self.send_response(200)
        self.end_headers()

    def do_POST(self):
        if self.path != '/do_update':
            self.send_error(404)
            return

        if 'Content-Length' not in self.headers:
            self.send_error(400)
            return

        content_length = int(self.headers['Content-Length'])
        payload_string = self.rfile.read(content_length)
        logging.info('Got a message for %s' % payload_string)

        # First write something so that the nginx server upstream doesn't time out
        # even if building the book takes a while.
        self.wfile.write('%s ' % self.protocol_version)

        if self.download_rdf():
            self.send_error(500)
            return

        if not process_queued_update(payload_string):
            self.wfile.write('%d %s\r\n' % (500, 'Error'))
            self.send_header('Connection', 'close')
            self.end_headers()
            return

        self.wfile.write('%d %s\r\n' % (200, 'OK'))
        self.send_header('Connection', 'close')
        self.end_headers()

class cd:
    """Context manager for changing the current working directory"""
    def __init__(self, newPath):
        self.newPath = os.path.expanduser(newPath)

    def __enter__(self):
        self.savedPath = os.getcwd()
        os.chdir(self.newPath)

    def __exit__(self, etype, value, traceback):
        os.chdir(self.savedPath)

def make_ebook(b, tag):
    time0 = time.time()
    with cd(b.local_path):
        ebooks.build_epub()
        logging.info('epub for {} took {} seconds'.format(b.local_path, time.time() - time0))
        if os.path.exists("book.epub"):
            subprocess.check_call(('ebook-convert', 'book.epub', 'book.mobi'))
            subprocess.check_call(('xvfb-run', 'ebook-convert', 'book.epub', 'book.pdf'))
        logging.info('ebooks for {} took {} seconds'.format(b.local_path, time.time() - time0))
        ebooks.add_release(b, tag, ['book.epub', 'book.mobi', 'book.pdf'])

def ratelimit_remaining(book):
    try:
        return book.github_repo.github.ratelimit_remaining
    except:
        logging.error("couldn't get rate limit")
        return -1
        
def process_queued_update(repo_name):
    repo_name_tag = [repo_name] if isinstance(repo_name, int) else repo_name.split(' ', 1)
    (repo_name, tag) = repo_name_tag if len(repo_name_tag) == 2 else (repo_name, None)
    # intialize book
    b = gitenberg.actions.get_book(repo_name)
    ratelimit_start = ratelimit_remaining(b)
    if b.local_path:
        b.remove()
    try:
        b.clone_from_github() # if no local version, clones

        # if it previously existed as a local repo, need to pull
        repo = b.local_repo.git
        if not repo.remote('origin'): # must exist
            logging.error("No origin for %s" % repo_name)
            return False
        repo.remote('origin').pull()

        commit_message = str(b.parse_book_metadata()) # in case this changed

        # checks for covers
        # if none, makes one, adds to metadata
        commit_message += str(b.add_covers()) # checks for covers

        if tag:
            b.meta.metadata['_version'] = tag
            commit_message += "tag {}".format(tag)

        b.save_meta() # save the new metadata in yaml format

        b.local_repo.add_all_files() # untracked only
        repo.git.add(update=True) # tracked ones too

        if repo.git.status("--porcelain"):
            logging.info('Have changes, so pushing and then building')
            # We made changes to the repo, so commit them.
            repo.index.commit(commit_message)

            # returns a list, one PushInfo per head. We have one head
            ret = repo.remote('origin').push(repo.refs.master)[0]
            if ret.flags & git.remote.PushInfo.ERROR:
                logging.error('Pushing returned %s' % ret)
                return False
        else:
            logging.info('No changes')
        if tag:
            make_ebook(b, tag) # make ebook files
            logging.info('Ebook Files made')
        
        ratelimit_end = ratelimit_remaining(b)
        logging.info("Used {} api calls; {} remaining".format(
            ratelimit_start - ratelimit_end, ratelimit_end
        ))
        return webhooks.gitensite(b) and webhooks.unglueit(b)
    finally:
        # Make sure to always remove it to avoid filling up the disk.
        if b.local_path:
            b.remove()

    return True

if __name__ == '__main__':
    arguments = docopt(__doc__, version=__version__)

    util.setup_logging(arguments)

    port = int(arguments.get('<port>', '80'))

    server = BaseHTTPServer.HTTPServer(('0.0.0.0', port), RequestHandler)
    try:
        server.serve_forever()
    except KeyboardInterrupt:
        pass
    server.server_close()
